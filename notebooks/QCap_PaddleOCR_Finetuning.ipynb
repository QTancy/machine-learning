{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QQ9_bdl6_Y42"
      },
      "source": [
        "# Importing All Necessary Libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iUnZhMI44p-M",
        "outputId": "ab10e533-ff7d-4f34-9595-9bd0bc20761d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_50E4ZYN45Lb",
        "outputId": "d01ec603-1097-4629-8b93-5b8642c6180f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/DBS/invoices-and-receipts_ocr_v2/data (4 files)\n",
            " └── valid-00000-of-00001-a34ca26ac5064310.parquet\n",
            " └── test-00000-of-00001-5e49167f3ab7fa83.parquet\n",
            " └── train-00001-of-00002-2e5ab49d1f705bff.parquet\n",
            " └── train-00000-of-00002-801e1aea0f0adc30.parquet\n",
            "\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "\n",
        "folder_path = \"/content/drive/MyDrive/DBS/invoices-and-receipts_ocr_v2/data\"\n",
        "\n",
        "for root, dirs, files in os.walk(folder_path):\n",
        "    print(f\"{root} ({len(files)} files)\")\n",
        "    for name in files[:5]:\n",
        "        print(\" └──\", name)\n",
        "    print()\n",
        "    break\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "vrVLsod_3UmK"
      },
      "outputs": [],
      "source": [
        "!pip install -q pandas pyarrow"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "On8xUjjy3o0f",
        "outputId": "4777cdd0-2aac-4e8b-8968-525393987709"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in links: https://www.paddlepaddle.org.cn/whl/mkl/avx/stable.html\n",
            "Collecting paddlepaddle-gpu==2.5.1\n",
            "  Downloading paddlepaddle_gpu-2.5.1-cp311-cp311-manylinux1_x86_64.whl.metadata (8.6 kB)\n",
            "Requirement already satisfied: httpx in /usr/local/lib/python3.11/dist-packages (from paddlepaddle-gpu==2.5.1) (0.28.1)\n",
            "Requirement already satisfied: numpy>=1.13 in /usr/local/lib/python3.11/dist-packages (from paddlepaddle-gpu==2.5.1) (2.0.2)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.11/dist-packages (from paddlepaddle-gpu==2.5.1) (11.2.1)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.11/dist-packages (from paddlepaddle-gpu==2.5.1) (4.4.2)\n",
            "Collecting astor (from paddlepaddle-gpu==2.5.1)\n",
            "  Downloading astor-0.8.1-py2.py3-none-any.whl.metadata (4.2 kB)\n",
            "Collecting paddle-bfloat==0.1.7 (from paddlepaddle-gpu==2.5.1)\n",
            "  Downloading paddle_bfloat-0.1.7-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (202 bytes)\n",
            "Collecting opt-einsum==3.3.0 (from paddlepaddle-gpu==2.5.1)\n",
            "  Downloading opt_einsum-3.3.0-py3-none-any.whl.metadata (6.5 kB)\n",
            "Requirement already satisfied: protobuf>=3.20.2 in /usr/local/lib/python3.11/dist-packages (from paddlepaddle-gpu==2.5.1) (5.29.5)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.11/dist-packages (from httpx->paddlepaddle-gpu==2.5.1) (4.9.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx->paddlepaddle-gpu==2.5.1) (2025.4.26)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx->paddlepaddle-gpu==2.5.1) (1.0.9)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.11/dist-packages (from httpx->paddlepaddle-gpu==2.5.1) (3.10)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx->paddlepaddle-gpu==2.5.1) (0.16.0)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio->httpx->paddlepaddle-gpu==2.5.1) (1.3.1)\n",
            "Requirement already satisfied: typing_extensions>=4.5 in /usr/local/lib/python3.11/dist-packages (from anyio->httpx->paddlepaddle-gpu==2.5.1) (4.14.0)\n",
            "Downloading paddlepaddle_gpu-2.5.1-cp311-cp311-manylinux1_x86_64.whl (541.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m541.0/541.0 MB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading opt_einsum-3.3.0-py3-none-any.whl (65 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m65.5/65.5 kB\u001b[0m \u001b[31m6.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading paddle_bfloat-0.1.7-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (383 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m383.5/383.5 kB\u001b[0m \u001b[31m37.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading astor-0.8.1-py2.py3-none-any.whl (27 kB)\n",
            "Installing collected packages: paddle-bfloat, opt-einsum, astor, paddlepaddle-gpu\n",
            "  Attempting uninstall: opt-einsum\n",
            "    Found existing installation: opt_einsum 3.4.0\n",
            "    Uninstalling opt_einsum-3.4.0:\n",
            "      Successfully uninstalled opt_einsum-3.4.0\n",
            "Successfully installed astor-0.8.1 opt-einsum-3.3.0 paddle-bfloat-0.1.7 paddlepaddle-gpu-2.5.1\n"
          ]
        }
      ],
      "source": [
        "!pip install paddlepaddle-gpu==2.5.1 -f https://www.paddlepaddle.org.cn/whl/mkl/avx/stable.html"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "05xiyjX95-Yc",
        "outputId": "a62e0423-bdca-48d3-f9ac-2c4d8bf0940c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'PaddleOCR'...\n",
            "remote: Enumerating objects: 237435, done.\u001b[K\n",
            "remote: Counting objects: 100% (1723/1723), done.\u001b[K\n",
            "remote: Compressing objects: 100% (366/366), done.\u001b[K\n",
            "remote: Total 237435 (delta 1413), reused 1585 (delta 1333), pack-reused 235712 (from 3)\u001b[K\n",
            "Receiving objects: 100% (237435/237435), 1.25 GiB | 17.63 MiB/s, done.\n",
            "Resolving deltas: 100% (187243/187243), done.\n",
            "Updating files: 100% (1873/1873), done.\n",
            "/content/PaddleOCR\n",
            "Requirement already satisfied: shapely in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 1)) (2.1.1)\n",
            "Requirement already satisfied: scikit-image in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 2)) (0.25.2)\n",
            "Collecting pyclipper (from -r requirements.txt (line 3))\n",
            "  Downloading pyclipper-1.3.0.post6-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (9.0 kB)\n",
            "Collecting lmdb (from -r requirements.txt (line 4))\n",
            "  Downloading lmdb-1.6.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.1 kB)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 5)) (4.67.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 6)) (2.0.2)\n",
            "Collecting rapidfuzz (from -r requirements.txt (line 7))\n",
            "  Downloading rapidfuzz-3.13.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 8)) (4.11.0.86)\n",
            "Requirement already satisfied: opencv-contrib-python in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 9)) (4.11.0.86)\n",
            "Requirement already satisfied: cython in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 10)) (3.0.12)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 11)) (11.2.1)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 12)) (6.0.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 13)) (2.32.3)\n",
            "Requirement already satisfied: albumentations in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 14)) (2.0.8)\n",
            "Requirement already satisfied: albucore in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 16)) (0.0.24)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 17)) (24.2)\n",
            "Requirement already satisfied: scipy>=1.11.4 in /usr/local/lib/python3.11/dist-packages (from scikit-image->-r requirements.txt (line 2)) (1.15.3)\n",
            "Requirement already satisfied: networkx>=3.0 in /usr/local/lib/python3.11/dist-packages (from scikit-image->-r requirements.txt (line 2)) (3.5)\n",
            "Requirement already satisfied: imageio!=2.35.0,>=2.33 in /usr/local/lib/python3.11/dist-packages (from scikit-image->-r requirements.txt (line 2)) (2.37.0)\n",
            "Requirement already satisfied: tifffile>=2022.8.12 in /usr/local/lib/python3.11/dist-packages (from scikit-image->-r requirements.txt (line 2)) (2025.6.1)\n",
            "Requirement already satisfied: lazy-loader>=0.4 in /usr/local/lib/python3.11/dist-packages (from scikit-image->-r requirements.txt (line 2)) (0.4)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->-r requirements.txt (line 13)) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->-r requirements.txt (line 13)) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->-r requirements.txt (line 13)) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->-r requirements.txt (line 13)) (2025.4.26)\n",
            "Requirement already satisfied: pydantic>=2.9.2 in /usr/local/lib/python3.11/dist-packages (from albumentations->-r requirements.txt (line 14)) (2.11.5)\n",
            "Requirement already satisfied: opencv-python-headless>=4.9.0.80 in /usr/local/lib/python3.11/dist-packages (from albumentations->-r requirements.txt (line 14)) (4.11.0.86)\n",
            "Requirement already satisfied: stringzilla>=3.10.4 in /usr/local/lib/python3.11/dist-packages (from albucore->-r requirements.txt (line 16)) (3.12.5)\n",
            "Requirement already satisfied: simsimd>=5.9.2 in /usr/local/lib/python3.11/dist-packages (from albucore->-r requirements.txt (line 16)) (6.4.7)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.9.2->albumentations->-r requirements.txt (line 14)) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.9.2->albumentations->-r requirements.txt (line 14)) (2.33.2)\n",
            "Requirement already satisfied: typing-extensions>=4.12.2 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.9.2->albumentations->-r requirements.txt (line 14)) (4.14.0)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.9.2->albumentations->-r requirements.txt (line 14)) (0.4.1)\n",
            "Downloading pyclipper-1.3.0.post6-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (969 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m969.6/969.6 kB\u001b[0m \u001b[31m54.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading lmdb-1.6.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (297 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m297.8/297.8 kB\u001b[0m \u001b[31m30.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading rapidfuzz-3.13.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m96.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pyclipper, lmdb, rapidfuzz\n",
            "Successfully installed lmdb-1.6.2 pyclipper-1.3.0.post6 rapidfuzz-3.13.0\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/PaddlePaddle/PaddleOCR.git\n",
        "%cd PaddleOCR\n",
        "!pip install -r requirements.txt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RQMnx9GQ6FLh",
        "outputId": "04dcbfd2-8512-4269-e676-7460c6420f4d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/6.3 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━\u001b[0m \u001b[32m6.0/6.3 MB\u001b[0m \u001b[31m143.9 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.3/6.3 MB\u001b[0m \u001b[31m84.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/344.8 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m344.8/344.8 kB\u001b[0m \u001b[31m27.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/2.3 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.3/2.3 MB\u001b[0m \u001b[31m81.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "!pip install -q scikit-image visualdl"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "2GTG_0Vr9WgU",
        "outputId": "222a422a-1a26-4697-f07a-c50723137248"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2025-06-08 04:24:43--  https://nz2.archive.ubuntu.com/ubuntu/pool/main/o/openssl/libssl1.1_1.1.1f-1ubuntu2.24_amd64.deb\n",
            "Resolving nz2.archive.ubuntu.com (nz2.archive.ubuntu.com)... 91.189.91.83, 185.125.190.36, 185.125.190.82, ...\n",
            "Connecting to nz2.archive.ubuntu.com (nz2.archive.ubuntu.com)|91.189.91.83|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1323248 (1.3M) [application/vnd.debian.binary-package]\n",
            "Saving to: ‘libssl1.1_1.1.1f-1ubuntu2.24_amd64.deb’\n",
            "\n",
            "libssl1.1_1.1.1f-1u 100%[===================>]   1.26M   928KB/s    in 1.4s    \n",
            "\n",
            "2025-06-08 04:24:45 (928 KB/s) - ‘libssl1.1_1.1.1f-1ubuntu2.24_amd64.deb’ saved [1323248/1323248]\n",
            "\n",
            "Selecting previously unselected package libssl1.1:amd64.\n",
            "(Reading database ... 126111 files and directories currently installed.)\n",
            "Preparing to unpack libssl1.1_1.1.1f-1ubuntu2.24_amd64.deb ...\n",
            "Unpacking libssl1.1:amd64 (1.1.1f-1ubuntu2.24) ...\n",
            "Setting up libssl1.1:amd64 (1.1.1f-1ubuntu2.24) ...\n",
            "debconf: unable to initialize frontend: Dialog\n",
            "debconf: (No usable dialog-like program is installed, so the dialog based frontend cannot be used. at /usr/share/perl5/Debconf/FrontEnd/Dialog.pm line 78.)\n",
            "debconf: falling back to frontend: Readline\n",
            "debconf: unable to initialize frontend: Readline\n",
            "debconf: (This frontend requires a controlling tty.)\n",
            "debconf: falling back to frontend: Teletype\n",
            "Processing triggers for libc-bin (2.35-0ubuntu3.8) ...\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind_2_0.so.3 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind_2_5.so.3 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind.so.3 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libhwloc.so.15 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libur_adapter_opencl.so.0 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libur_adapter_level_zero.so.0 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtcm.so.1 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbmalloc.so.2 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbb.so.12 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtcm_debug.so.1 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libumf.so.0 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libur_loader.so.0 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbmalloc_proxy.so.2 is not a symbolic link\n",
            "\n",
            "Package: libssl1.1\n",
            "Status: install ok installed\n",
            "Priority: optional\n",
            "Section: libs\n",
            "Installed-Size: 4034\n",
            "Maintainer: Ubuntu Developers <ubuntu-devel-discuss@lists.ubuntu.com>\n",
            "Architecture: amd64\n",
            "Multi-Arch: same\n",
            "Source: openssl\n",
            "Version: 1.1.1f-1ubuntu2.24\n",
            "Depends: libc6 (>= 2.25), debconf (>= 0.5) | debconf-2.0\n",
            "Breaks: isync (<< 1.3.0-2), lighttpd (<< 1.4.49-2), python-boto (<< 2.44.0-1.1), python-httplib2 (<< 0.11.3-1), python-imaplib2 (<< 2.57-5), python3-boto (<< 2.44.0-1.1), python3-imaplib2 (<< 2.57-5)\n",
            "Description: Secure Sockets Layer toolkit - shared libraries\n",
            " This package is part of the OpenSSL project's implementation of the SSL\n",
            " and TLS cryptographic protocols for secure communication over the\n",
            " Internet.\n",
            " .\n",
            " It provides the libssl and libcrypto shared libraries.\n",
            "Homepage: https://www.openssl.org/\n",
            "Original-Maintainer: Debian OpenSSL Team <pkg-openssl-devel@lists.alioth.debian.org>\n",
            "/usr/lib/x86_64-linux-gnu/libssl.so.1.1\n"
          ]
        }
      ],
      "source": [
        "!wget https://nz2.archive.ubuntu.com/ubuntu/pool/main/o/openssl/libssl1.1_1.1.1f-1ubuntu2.24_amd64.deb\n",
        "!sudo dpkg -i libssl1.1_1.1.1f-1ubuntu2.24_amd64.deb\n",
        "!dpkg -s libssl1.1\n",
        "!find / -name \"libssl.so.1.1\" 2>/dev/null"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u3hrTZXB9HsH",
        "outputId": "1cefda6c-9269-476c-9b5c-47a5cf55132f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.5.1\n",
            "True\n"
          ]
        }
      ],
      "source": [
        "import paddle\n",
        "print(paddle.__version__)\n",
        "print(paddle.is_compiled_with_cuda())"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "paddle.device.cuda.empty_cache()"
      ],
      "metadata": {
        "id": "fCkTTEoVBBX6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kPO9a-eD_fqP"
      },
      "source": [
        "# Mounting Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Bethnj8q5Jmq",
        "outputId": "af58f717-8865-41b7-ce41-c0c4fb3f4d84"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Jumlah data: 2843\n",
            "Kolom: ['image', 'id', 'parsed_data', 'raw_data']\n",
            "Contoh: image          {'bytes': b'\\xff\\xd8\\xff\\xe0\\x00\\x10JFIF\\x00\\x...\n",
            "id                                                             0\n",
            "parsed_data    {\"xml\": \"\", \"json\": \"\\\"{\\\\\\\"line_items\\\\\\\": [{...\n",
            "raw_data       {\"ocr_words\": \"['1%', 'Nasi Campur Bali', '75,...\n",
            "Name: 0, dtype: object\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "\n",
        "data_path = folder_path\n",
        "\n",
        "df1 = pd.read_parquet(f\"{data_path}/train-00000-of-00002-801e1aea0f0adc30.parquet\")\n",
        "df2 = pd.read_parquet(f\"{data_path}/train-00001-of-00002-2e5ab49d1f705bff.parquet\")\n",
        "\n",
        "df = pd.concat([df1, df2]).reset_index(drop=True)\n",
        "\n",
        "print(\"Jumlah data:\", len(df))\n",
        "print(\"Kolom:\", df.columns.tolist())\n",
        "print(\"Contoh:\", df.iloc[0])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UiOq8dY1_jTG"
      },
      "source": [
        "# Parsing Data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6yPT0SPLzf8B"
      },
      "source": [
        "```json\n",
        "train_images/img_001.jpg\t[{\"transcription\": \"hello\", \"points\": [[50, 30], [150, 30], [150, 80], [50, 80]]}]\n",
        "train_images/img_002.jpg\t[{\"transcription\": \"world\", \"points\": [[60, 20], [160, 20], [160, 70], [60, 70]]}]\n",
        "```\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import json\n",
        "import pandas as pd\n",
        "from PIL import Image\n",
        "from io import BytesIO\n",
        "from ast import literal_eval\n",
        "from tqdm import tqdm\n",
        "\n",
        "# BACA DATA PARQUET\n",
        "data_path = folder_path\n",
        "df1 = pd.read_parquet(f\"{data_path}/train-00000-of-00002-801e1aea0f0adc30.parquet\")\n",
        "df2 = pd.read_parquet(f\"{data_path}/train-00001-of-00002-2e5ab49d1f705bff.parquet\")\n",
        "df = pd.concat([df1, df2]).reset_index(drop=True)\n",
        "\n",
        "# OUTPUT FOLDER & FILE\n",
        "output_dir = \"/content/rec_train_images\"\n",
        "label_file = \"/content/rec_train_label.txt\"\n",
        "os.makedirs(output_dir, exist_ok=True)\n",
        "\n",
        "# MAKSIMAL DATA\n",
        "MAX_BOXES = 30\n",
        "count = 0\n",
        "idx_global = 0\n",
        "\n",
        "# LOOP DAN TULIS LABEL + CROP\n",
        "with open(label_file, \"w\", encoding=\"utf-8\") as f:\n",
        "    for i, row in tqdm(df.iterrows(), total=len(df)):\n",
        "        if count >= MAX_BOXES:\n",
        "            break\n",
        "\n",
        "        try:\n",
        "            img = Image.open(BytesIO(row[\"image\"][\"bytes\"])).convert(\"RGB\")\n",
        "            raw = json.loads(row[\"raw_data\"])\n",
        "            ocr_boxes = literal_eval(raw[\"ocr_boxes\"])\n",
        "        except Exception as e:\n",
        "            continue\n",
        "\n",
        "        for j, (box, (text, conf)) in enumerate(ocr_boxes):\n",
        "            if not text.strip():\n",
        "                continue\n",
        "            try:\n",
        "                points = [[float(x), float(y)] for x, y in box]\n",
        "                xs = [p[0] for p in points]\n",
        "                ys = [p[1] for p in points]\n",
        "                min_x, max_x = int(min(xs)), int(max(xs))\n",
        "                min_y, max_y = int(min(ys)), int(max(ys))\n",
        "                crop = img.crop((min_x, min_y, max_x, max_y))\n",
        "                crop_path = os.path.join(output_dir, f\"img_{idx_global:05d}.jpg\")\n",
        "                crop.save(crop_path)\n",
        "\n",
        "                clean_text = text.replace('\\n', ' ').strip()\n",
        "                f.write(f\"{crop_path}\\t{clean_text}\\n\")\n",
        "\n",
        "                idx_global += 1\n",
        "                count += 1\n",
        "                if count >= MAX_BOXES:\n",
        "                    break\n",
        "            except:\n",
        "                continue\n",
        "\n",
        "print(f\"✅ Selesai: {count} gambar disiapkan di {output_dir}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1DMfQ-e15a_D",
        "outputId": "8a31e432-f8cd-488d-8d5c-fb07751cc281"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 1/2843 [00:00<02:59, 15.84it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Selesai: 30 gambar disiapkan di /content/rec_train_images\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from PIL import Image\n",
        "import os\n",
        "\n",
        "label_file = \"/content/rec_train_label.txt\"\n",
        "lines = open(label_file, encoding=\"utf-8\").readlines()\n",
        "clean_lines = []\n",
        "\n",
        "for line in lines:\n",
        "    path, text = line.strip().split(\"\\t\")\n",
        "    try:\n",
        "        img = Image.open(path).convert(\"RGB\")\n",
        "        img.verify()  # Check image not broken\n",
        "        clean_lines.append(f\"{path}\\t{text}\")\n",
        "    except:\n",
        "        print(\"❌ rusak:\", path)\n",
        "\n",
        "# Overwrite only valid lines\n",
        "with open(label_file, \"w\", encoding=\"utf-8\") as f:\n",
        "    f.write(\"\\n\".join(clean_lines))\n",
        "\n",
        "print(f\"✅ Label valid: {len(clean_lines)}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QFFy_KsqC1k2",
        "outputId": "3a66516c-e57b-4bc7-8cf5-ceedad42792b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Label valid: 30\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 389
        },
        "id": "5ZEcQGRu5QXR",
        "outputId": "ef93cb88-bbcf-4811-b0b9-1edccb6fb28f"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: '/content/drive/MyDrive/Dicoding-Capstone-Qtancy/invoices-and-receipts_ocr_v2/data/train-00000-of-00002-801e1aea0f0adc30.parquet'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-19-9e517e3c534c>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0mdata_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"/content/drive/MyDrive/Dicoding-Capstone-Qtancy/invoices-and-receipts_ocr_v2/data\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0mdf1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_parquet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"{data_path}/train-00000-of-00002-801e1aea0f0adc30.parquet\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0mdf2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_parquet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"{data_path}/train-00001-of-00002-2e5ab49d1f705bff.parquet\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdf1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdf2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/parquet.py\u001b[0m in \u001b[0;36mread_parquet\u001b[0;34m(path, engine, columns, storage_options, use_nullable_dtypes, dtype_backend, filesystem, filters, **kwargs)\u001b[0m\n\u001b[1;32m    665\u001b[0m     \u001b[0mcheck_dtype_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype_backend\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    666\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 667\u001b[0;31m     return impl.read(\n\u001b[0m\u001b[1;32m    668\u001b[0m         \u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    669\u001b[0m         \u001b[0mcolumns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/parquet.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, path, columns, filters, use_nullable_dtypes, dtype_backend, storage_options, filesystem, **kwargs)\u001b[0m\n\u001b[1;32m    265\u001b[0m             \u001b[0mto_pandas_kwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"split_blocks\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m  \u001b[0;31m# type: ignore[assignment]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    266\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 267\u001b[0;31m         path_or_handle, handles, filesystem = _get_path_or_handle(\n\u001b[0m\u001b[1;32m    268\u001b[0m             \u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    269\u001b[0m             \u001b[0mfilesystem\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/parquet.py\u001b[0m in \u001b[0;36m_get_path_or_handle\u001b[0;34m(path, fs, storage_options, mode, is_dir)\u001b[0m\n\u001b[1;32m    138\u001b[0m         \u001b[0;31m# fsspec resources can also point to directories\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    139\u001b[0m         \u001b[0;31m# this branch is used for example when reading from non-fsspec URLs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 140\u001b[0;31m         handles = get_handle(\n\u001b[0m\u001b[1;32m    141\u001b[0m             \u001b[0mpath_or_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_text\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstorage_options\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstorage_options\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    142\u001b[0m         )\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    880\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    881\u001b[0m             \u001b[0;31m# Binary mode\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 882\u001b[0;31m             \u001b[0mhandle\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    883\u001b[0m         \u001b[0mhandles\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    884\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/drive/MyDrive/Dicoding-Capstone-Qtancy/invoices-and-receipts_ocr_v2/data/train-00000-of-00002-801e1aea0f0adc30.parquet'"
          ]
        }
      ],
      "source": [
        "\"\"\"\n",
        "import os\n",
        "import json\n",
        "import pandas as pd\n",
        "from PIL import Image\n",
        "from io import BytesIO\n",
        "from ast import literal_eval\n",
        "from tqdm import tqdm\n",
        "\n",
        "data_path = \"/content/drive/MyDrive/Dicoding-Capstone-Qtancy/invoices-and-receipts_ocr_v2/data\"\n",
        "df1 = pd.read_parquet(f\"{data_path}/train-00000-of-00002-801e1aea0f0adc30.parquet\")\n",
        "df2 = pd.read_parquet(f\"{data_path}/train-00001-of-00002-2e5ab49d1f705bff.parquet\")\n",
        "df = pd.concat([df1, df2]).reset_index(drop=True)\n",
        "output_dir = \"/content/rec_train_images\"\n",
        "os.makedirs(output_dir, exist_ok=True)\n",
        "label_file = \"/content/rec_train_label.txt\"\n",
        "MAX_BOXES = 200\n",
        "count = 0\n",
        "idx_global = 0\n",
        "with open(label_file, \"w\", encoding=\"utf-8\") as f:\n",
        "    for i, row in tqdm(df.iterrows(), total=len(df)):\n",
        "        try:\n",
        "            img = Image.open(BytesIO(row[\"image\"][\"bytes\"])).convert(\"RGB\")\n",
        "            raw = json.loads(row[\"raw_data\"])\n",
        "            ocr_boxes = literal_eval(raw[\"ocr_boxes\"])\n",
        "        except Exception as e:\n",
        "            continue\n",
        "\n",
        "        for j, (box, (text, conf)) in enumerate(ocr_boxes):\n",
        "            if not text.strip():\n",
        "                continue\n",
        "            try:\n",
        "                points = [[float(x), float(y)] for x, y in box]\n",
        "                xs = [p[0] for p in points]\n",
        "                ys = [p[1] for p in points]\n",
        "                min_x, max_x = int(min(xs)), int(max(xs))\n",
        "                min_y, max_y = int(min(ys)), int(max(ys))\n",
        "                crop = img.crop((min_x, min_y, max_x, max_y))\n",
        "                crop_path = os.path.join(output_dir, f\"img_{idx_global:05d}.jpg\")\n",
        "                crop.save(crop_path)\n",
        "\n",
        "                clean_text = text.replace('\\n', ' ').strip()\n",
        "                f.write(f\"{crop_path}\\t{clean_text}\\n\")\n",
        "                idx_global += 1\n",
        "            except:\n",
        "                continue\n",
        "\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tksK-Fs13h8a",
        "outputId": "98e714d2-e6e6-40ff-aff4-34021ddee6f2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ File /content/rec_config.yml berhasil dibuat!\n"
          ]
        }
      ],
      "source": [
        "rec_yaml = \"\"\"\n",
        "Global:\n",
        "  use_gpu: True\n",
        "  epoch_num: 50\n",
        "  save_model_dir: ./output/rec\n",
        "  log_smooth_window: 20\n",
        "  print_batch_step: 1\n",
        "  save_epoch_step: 5\n",
        "  eval_batch_step: [0, 200]\n",
        "  pretrained_model: null\n",
        "  checkpoints: null\n",
        "  save_inference_dir: null\n",
        "  use_visualdl: False\n",
        "  infer_img: /content/rec_train_images/img_00000.jpg\n",
        "  character_dict_path: ppocr/utils/dict/en_dict.txt\n",
        "  max_text_length: 25\n",
        "  save_res_path: ./output/rec/predicts.txt\n",
        "\n",
        "Architecture:\n",
        "  model_type: rec\n",
        "  algorithm: CRNN\n",
        "  Backbone:\n",
        "    name: ResNet\n",
        "    layers: 34\n",
        "  Neck:\n",
        "    name: SequenceEncoder\n",
        "    encoder_type: rnn\n",
        "    hidden_size: 256\n",
        "  Head:\n",
        "    name: CTCHead\n",
        "    fc_decay: 0.0001\n",
        "\n",
        "Loss:\n",
        "  name: CTCLoss\n",
        "\n",
        "Optimizer:\n",
        "  name: Adam\n",
        "  beta1: 0.9\n",
        "  beta2: 0.999\n",
        "  lr:\n",
        "    learning_rate: 0.001\n",
        "  regularizer:\n",
        "    name: 'L2'\n",
        "    factor: 0.0001\n",
        "\n",
        "PostProcess:\n",
        "  name: CTCLabelDecode\n",
        "\n",
        "Metric:\n",
        "  name: RecMetric\n",
        "  main_indicator: acc\n",
        "\n",
        "Train:\n",
        "  dataset:\n",
        "    name: SimpleDataSet\n",
        "    data_dir: /content\n",
        "    label_file_list: [\"/content/rec_train_label.txt\"]\n",
        "    transforms:\n",
        "      - DecodeImage:\n",
        "          img_mode: BGR\n",
        "          channel_first: False\n",
        "      - RecAug: {}\n",
        "      - CTCLabelEncode: {}\n",
        "      - RecResizeImg:\n",
        "          image_shape: [3, 32, 100]\n",
        "      - KeepKeys:\n",
        "          keep_keys: ['image', 'label', 'length']\n",
        "  loader:\n",
        "    batch_size_per_card: 1\n",
        "    num_workers: 0\n",
        "    shuffle: True\n",
        "    drop_last: False  # ✅ TAMBAHKAN INI\n",
        "\n",
        "Eval:\n",
        "  dataset:\n",
        "    name: SimpleDataSet\n",
        "    data_dir: /content\n",
        "    label_file_list: [\"/content/rec_train_label.txt\"]\n",
        "    transforms:\n",
        "      - DecodeImage:\n",
        "          img_mode: BGR\n",
        "          channel_first: False\n",
        "      - CTCLabelEncode: {}\n",
        "      - RecResizeImg:\n",
        "          image_shape: [3, 32, 100]\n",
        "      - KeepKeys:\n",
        "          keep_keys: ['image', 'label', 'length']\n",
        "  loader:\n",
        "    batch_size_per_card: 1\n",
        "    num_workers: 0\n",
        "    shuffle: False\n",
        "    drop_last: False  # ✅ TAMBAHKAN INI\n",
        "\"\"\"\n",
        "\n",
        "with open(\"/content/rec_config.yml\", \"w\") as f:\n",
        "    f.write(rec_yaml)\n",
        "\n",
        "print(\"✅ File /content/rec_config.yml berhasil dibuat!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eSKnp7Zh_tM9"
      },
      "source": [
        "# Fine Tuning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3seYU386AQ1x",
        "outputId": "7d089efc-4985-47ce-a72d-58654722e742"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🚨 Total gambar corrupt: 0\n"
          ]
        }
      ],
      "source": [
        "from PIL import Image\n",
        "\n",
        "with open(\"/content/rec_train_label.txt\", encoding=\"utf-8\") as f:\n",
        "    lines = f.readlines()\n",
        "\n",
        "corrupt = 0\n",
        "for line in lines:\n",
        "    path, _ = line.strip().split(\"\\t\")\n",
        "    try:\n",
        "        img = Image.open(path).convert(\"RGB\")\n",
        "        img.verify()\n",
        "    except Exception as e:\n",
        "        print(f\"❌ Corrupt: {path}\")\n",
        "        corrupt += 1\n",
        "\n",
        "print(f\"🚨 Total gambar corrupt: {corrupt}\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python tools/train.py -c /content/rec_config.yml -o Global.epoch_num=1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xNVyVMPBMRr5",
        "outputId": "d57b7f46-b788-4b23-c185-01d62b64bc38"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[2025/06/08 04:35:32] ppocr WARNING: Skipping import of the encryption module.\n",
            "[2025/06/08 04:35:33] ppocr INFO: Architecture : \n",
            "[2025/06/08 04:35:33] ppocr INFO:     Backbone : \n",
            "[2025/06/08 04:35:33] ppocr INFO:         layers : 34\n",
            "[2025/06/08 04:35:33] ppocr INFO:         name : ResNet\n",
            "[2025/06/08 04:35:33] ppocr INFO:     Head : \n",
            "[2025/06/08 04:35:33] ppocr INFO:         fc_decay : 0.0001\n",
            "[2025/06/08 04:35:33] ppocr INFO:         name : CTCHead\n",
            "[2025/06/08 04:35:33] ppocr INFO:     Neck : \n",
            "[2025/06/08 04:35:33] ppocr INFO:         encoder_type : rnn\n",
            "[2025/06/08 04:35:33] ppocr INFO:         hidden_size : 256\n",
            "[2025/06/08 04:35:33] ppocr INFO:         name : SequenceEncoder\n",
            "[2025/06/08 04:35:33] ppocr INFO:     algorithm : CRNN\n",
            "[2025/06/08 04:35:33] ppocr INFO:     model_type : rec\n",
            "[2025/06/08 04:35:33] ppocr INFO: Eval : \n",
            "[2025/06/08 04:35:33] ppocr INFO:     dataset : \n",
            "[2025/06/08 04:35:33] ppocr INFO:         data_dir : /content\n",
            "[2025/06/08 04:35:33] ppocr INFO:         label_file_list : ['/content/rec_train_label.txt']\n",
            "[2025/06/08 04:35:33] ppocr INFO:         name : SimpleDataSet\n",
            "[2025/06/08 04:35:33] ppocr INFO:         transforms : \n",
            "[2025/06/08 04:35:33] ppocr INFO:             DecodeImage : \n",
            "[2025/06/08 04:35:33] ppocr INFO:                 channel_first : False\n",
            "[2025/06/08 04:35:33] ppocr INFO:                 img_mode : BGR\n",
            "[2025/06/08 04:35:33] ppocr INFO:             CTCLabelEncode : \n",
            "[2025/06/08 04:35:33] ppocr INFO:             RecResizeImg : \n",
            "[2025/06/08 04:35:33] ppocr INFO:                 image_shape : [3, 32, 100]\n",
            "[2025/06/08 04:35:33] ppocr INFO:             KeepKeys : \n",
            "[2025/06/08 04:35:33] ppocr INFO:                 keep_keys : ['image', 'label', 'length']\n",
            "[2025/06/08 04:35:33] ppocr INFO:     loader : \n",
            "[2025/06/08 04:35:33] ppocr INFO:         batch_size_per_card : 1\n",
            "[2025/06/08 04:35:33] ppocr INFO:         drop_last : False\n",
            "[2025/06/08 04:35:33] ppocr INFO:         num_workers : 0\n",
            "[2025/06/08 04:35:33] ppocr INFO:         shuffle : False\n",
            "[2025/06/08 04:35:33] ppocr INFO: Global : \n",
            "[2025/06/08 04:35:33] ppocr INFO:     character_dict_path : ppocr/utils/dict/en_dict.txt\n",
            "[2025/06/08 04:35:33] ppocr INFO:     checkpoints : None\n",
            "[2025/06/08 04:35:33] ppocr INFO:     distributed : False\n",
            "[2025/06/08 04:35:33] ppocr INFO:     epoch_num : 1\n",
            "[2025/06/08 04:35:33] ppocr INFO:     eval_batch_step : [0, 200]\n",
            "[2025/06/08 04:35:33] ppocr INFO:     infer_img : /content/rec_train_images/img_00000.jpg\n",
            "[2025/06/08 04:35:33] ppocr INFO:     log_smooth_window : 20\n",
            "[2025/06/08 04:35:33] ppocr INFO:     max_text_length : 25\n",
            "[2025/06/08 04:35:33] ppocr INFO:     pretrained_model : None\n",
            "[2025/06/08 04:35:33] ppocr INFO:     print_batch_step : 1\n",
            "[2025/06/08 04:35:33] ppocr INFO:     save_epoch_step : 5\n",
            "[2025/06/08 04:35:33] ppocr INFO:     save_inference_dir : None\n",
            "[2025/06/08 04:35:33] ppocr INFO:     save_model_dir : ./output/rec\n",
            "[2025/06/08 04:35:33] ppocr INFO:     save_res_path : ./output/rec/predicts.txt\n",
            "[2025/06/08 04:35:33] ppocr INFO:     use_gpu : True\n",
            "[2025/06/08 04:35:33] ppocr INFO:     use_visualdl : False\n",
            "[2025/06/08 04:35:33] ppocr INFO: Loss : \n",
            "[2025/06/08 04:35:33] ppocr INFO:     name : CTCLoss\n",
            "[2025/06/08 04:35:33] ppocr INFO: Metric : \n",
            "[2025/06/08 04:35:33] ppocr INFO:     main_indicator : acc\n",
            "[2025/06/08 04:35:33] ppocr INFO:     name : RecMetric\n",
            "[2025/06/08 04:35:33] ppocr INFO: Optimizer : \n",
            "[2025/06/08 04:35:33] ppocr INFO:     beta1 : 0.9\n",
            "[2025/06/08 04:35:33] ppocr INFO:     beta2 : 0.999\n",
            "[2025/06/08 04:35:33] ppocr INFO:     lr : \n",
            "[2025/06/08 04:35:33] ppocr INFO:         learning_rate : 0.001\n",
            "[2025/06/08 04:35:33] ppocr INFO:     name : Adam\n",
            "[2025/06/08 04:35:33] ppocr INFO:     regularizer : \n",
            "[2025/06/08 04:35:33] ppocr INFO:         factor : 0.0001\n",
            "[2025/06/08 04:35:33] ppocr INFO:         name : L2\n",
            "[2025/06/08 04:35:33] ppocr INFO: PostProcess : \n",
            "[2025/06/08 04:35:33] ppocr INFO:     name : CTCLabelDecode\n",
            "[2025/06/08 04:35:33] ppocr INFO: Train : \n",
            "[2025/06/08 04:35:33] ppocr INFO:     dataset : \n",
            "[2025/06/08 04:35:33] ppocr INFO:         data_dir : /content\n",
            "[2025/06/08 04:35:33] ppocr INFO:         label_file_list : ['/content/rec_train_label.txt']\n",
            "[2025/06/08 04:35:33] ppocr INFO:         name : SimpleDataSet\n",
            "[2025/06/08 04:35:33] ppocr INFO:         transforms : \n",
            "[2025/06/08 04:35:33] ppocr INFO:             DecodeImage : \n",
            "[2025/06/08 04:35:33] ppocr INFO:                 channel_first : False\n",
            "[2025/06/08 04:35:33] ppocr INFO:                 img_mode : BGR\n",
            "[2025/06/08 04:35:33] ppocr INFO:             RecAug : \n",
            "[2025/06/08 04:35:33] ppocr INFO:             CTCLabelEncode : \n",
            "[2025/06/08 04:35:33] ppocr INFO:             RecResizeImg : \n",
            "[2025/06/08 04:35:33] ppocr INFO:                 image_shape : [3, 32, 100]\n",
            "[2025/06/08 04:35:33] ppocr INFO:             KeepKeys : \n",
            "[2025/06/08 04:35:33] ppocr INFO:                 keep_keys : ['image', 'label', 'length']\n",
            "[2025/06/08 04:35:33] ppocr INFO:     loader : \n",
            "[2025/06/08 04:35:33] ppocr INFO:         batch_size_per_card : 1\n",
            "[2025/06/08 04:35:33] ppocr INFO:         drop_last : False\n",
            "[2025/06/08 04:35:33] ppocr INFO:         num_workers : 0\n",
            "[2025/06/08 04:35:33] ppocr INFO:         shuffle : True\n",
            "[2025/06/08 04:35:33] ppocr INFO: profiler_options : None\n",
            "[2025/06/08 04:35:33] ppocr INFO: train with paddle 2.5.1 and device Place(gpu:0)\n",
            "[2025/06/08 04:35:33] ppocr INFO: Initialize indexes of datasets:['/content/rec_train_label.txt']\n",
            "[2025/06/08 04:35:33] ppocr INFO: Initialize indexes of datasets:['/content/rec_train_label.txt']\n",
            "W0608 04:35:33.339462  6061 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 7.5, Driver API Version: 12.4, Runtime API Version: 11.8\n",
            "W0608 04:35:33.340538  6061 gpu_resources.cc:149] device: 0, cuDNN Version: 90.2.\n",
            "[2025/06/08 04:35:33] ppocr INFO: train dataloader has 30 iters\n",
            "[2025/06/08 04:35:33] ppocr INFO: valid dataloader has 30 iters\n",
            "[2025/06/08 04:35:33] ppocr INFO: train from scratch\n",
            "[2025/06/08 04:35:33] ppocr INFO: During the training process, after the 0th iteration, an evaluation is run every 200 iterations\n",
            "\n",
            "\n",
            "--------------------------------------\n",
            "C++ Traceback (most recent call last):\n",
            "--------------------------------------\n",
            "No stack trace in paddle, may be caused by external reasons.\n",
            "\n",
            "----------------------\n",
            "Error Message Summary:\n",
            "----------------------\n",
            "FatalError: `Segmentation fault` is detected by the operating system.\n",
            "  [TimeInfo: *** Aborted at 1749357334 (unix time) try \"date -d @1749357334\" if you are using GNU date ***]\n",
            "  [SignalInfo: *** SIGSEGV (@0x0) received by PID 6061 (TID 0x7ee0290d7480) from PID 0 ***]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x8a4EMlT6ZOR",
        "outputId": "8abe92c8-ee0b-4c34-c282-2fe717421c2d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[2025/06/08 04:36:06] ppocr WARNING: Skipping import of the encryption module.\n",
            "[2025/06/08 04:36:06] ppocr INFO: Architecture : \n",
            "[2025/06/08 04:36:06] ppocr INFO:     Backbone : \n",
            "[2025/06/08 04:36:06] ppocr INFO:         layers : 34\n",
            "[2025/06/08 04:36:06] ppocr INFO:         name : ResNet\n",
            "[2025/06/08 04:36:06] ppocr INFO:     Head : \n",
            "[2025/06/08 04:36:06] ppocr INFO:         fc_decay : 0.0001\n",
            "[2025/06/08 04:36:06] ppocr INFO:         name : CTCHead\n",
            "[2025/06/08 04:36:06] ppocr INFO:     Neck : \n",
            "[2025/06/08 04:36:06] ppocr INFO:         encoder_type : rnn\n",
            "[2025/06/08 04:36:06] ppocr INFO:         hidden_size : 256\n",
            "[2025/06/08 04:36:06] ppocr INFO:         name : SequenceEncoder\n",
            "[2025/06/08 04:36:06] ppocr INFO:     algorithm : CRNN\n",
            "[2025/06/08 04:36:06] ppocr INFO:     model_type : rec\n",
            "[2025/06/08 04:36:06] ppocr INFO: Eval : \n",
            "[2025/06/08 04:36:06] ppocr INFO:     dataset : \n",
            "[2025/06/08 04:36:06] ppocr INFO:         data_dir : /content\n",
            "[2025/06/08 04:36:06] ppocr INFO:         label_file_list : ['/content/rec_train_label.txt']\n",
            "[2025/06/08 04:36:06] ppocr INFO:         name : SimpleDataSet\n",
            "[2025/06/08 04:36:06] ppocr INFO:         transforms : \n",
            "[2025/06/08 04:36:06] ppocr INFO:             DecodeImage : \n",
            "[2025/06/08 04:36:06] ppocr INFO:                 channel_first : False\n",
            "[2025/06/08 04:36:06] ppocr INFO:                 img_mode : BGR\n",
            "[2025/06/08 04:36:06] ppocr INFO:             CTCLabelEncode : \n",
            "[2025/06/08 04:36:06] ppocr INFO:             RecResizeImg : \n",
            "[2025/06/08 04:36:06] ppocr INFO:                 image_shape : [3, 32, 100]\n",
            "[2025/06/08 04:36:06] ppocr INFO:             KeepKeys : \n",
            "[2025/06/08 04:36:06] ppocr INFO:                 keep_keys : ['image', 'label', 'length']\n",
            "[2025/06/08 04:36:06] ppocr INFO:     loader : \n",
            "[2025/06/08 04:36:06] ppocr INFO:         batch_size_per_card : 1\n",
            "[2025/06/08 04:36:06] ppocr INFO:         drop_last : False\n",
            "[2025/06/08 04:36:06] ppocr INFO:         num_workers : 0\n",
            "[2025/06/08 04:36:06] ppocr INFO:         shuffle : False\n",
            "[2025/06/08 04:36:06] ppocr INFO: Global : \n",
            "[2025/06/08 04:36:06] ppocr INFO:     character_dict_path : ppocr/utils/dict/en_dict.txt\n",
            "[2025/06/08 04:36:06] ppocr INFO:     checkpoints : None\n",
            "[2025/06/08 04:36:06] ppocr INFO:     distributed : False\n",
            "[2025/06/08 04:36:06] ppocr INFO:     epoch_num : 50\n",
            "[2025/06/08 04:36:06] ppocr INFO:     eval_batch_step : [0, 200]\n",
            "[2025/06/08 04:36:06] ppocr INFO:     infer_img : /content/rec_train_images/img_00000.jpg\n",
            "[2025/06/08 04:36:06] ppocr INFO:     log_smooth_window : 20\n",
            "[2025/06/08 04:36:06] ppocr INFO:     max_text_length : 25\n",
            "[2025/06/08 04:36:06] ppocr INFO:     pretrained_model : None\n",
            "[2025/06/08 04:36:06] ppocr INFO:     print_batch_step : 1\n",
            "[2025/06/08 04:36:06] ppocr INFO:     save_epoch_step : 5\n",
            "[2025/06/08 04:36:06] ppocr INFO:     save_inference_dir : None\n",
            "[2025/06/08 04:36:06] ppocr INFO:     save_model_dir : ./output/rec\n",
            "[2025/06/08 04:36:06] ppocr INFO:     save_res_path : ./output/rec/predicts.txt\n",
            "[2025/06/08 04:36:06] ppocr INFO:     use_gpu : True\n",
            "[2025/06/08 04:36:06] ppocr INFO:     use_visualdl : False\n",
            "[2025/06/08 04:36:06] ppocr INFO: Loss : \n",
            "[2025/06/08 04:36:06] ppocr INFO:     name : CTCLoss\n",
            "[2025/06/08 04:36:06] ppocr INFO: Metric : \n",
            "[2025/06/08 04:36:06] ppocr INFO:     main_indicator : acc\n",
            "[2025/06/08 04:36:06] ppocr INFO:     name : RecMetric\n",
            "[2025/06/08 04:36:06] ppocr INFO: Optimizer : \n",
            "[2025/06/08 04:36:06] ppocr INFO:     beta1 : 0.9\n",
            "[2025/06/08 04:36:06] ppocr INFO:     beta2 : 0.999\n",
            "[2025/06/08 04:36:06] ppocr INFO:     lr : \n",
            "[2025/06/08 04:36:06] ppocr INFO:         learning_rate : 0.001\n",
            "[2025/06/08 04:36:06] ppocr INFO:     name : Adam\n",
            "[2025/06/08 04:36:06] ppocr INFO:     regularizer : \n",
            "[2025/06/08 04:36:06] ppocr INFO:         factor : 0.0001\n",
            "[2025/06/08 04:36:06] ppocr INFO:         name : L2\n",
            "[2025/06/08 04:36:06] ppocr INFO: PostProcess : \n",
            "[2025/06/08 04:36:06] ppocr INFO:     name : CTCLabelDecode\n",
            "[2025/06/08 04:36:06] ppocr INFO: Train : \n",
            "[2025/06/08 04:36:06] ppocr INFO:     dataset : \n",
            "[2025/06/08 04:36:06] ppocr INFO:         data_dir : /content\n",
            "[2025/06/08 04:36:06] ppocr INFO:         label_file_list : ['/content/rec_train_label.txt']\n",
            "[2025/06/08 04:36:06] ppocr INFO:         name : SimpleDataSet\n",
            "[2025/06/08 04:36:06] ppocr INFO:         transforms : \n",
            "[2025/06/08 04:36:06] ppocr INFO:             DecodeImage : \n",
            "[2025/06/08 04:36:06] ppocr INFO:                 channel_first : False\n",
            "[2025/06/08 04:36:06] ppocr INFO:                 img_mode : BGR\n",
            "[2025/06/08 04:36:06] ppocr INFO:             RecAug : \n",
            "[2025/06/08 04:36:06] ppocr INFO:             CTCLabelEncode : \n",
            "[2025/06/08 04:36:06] ppocr INFO:             RecResizeImg : \n",
            "[2025/06/08 04:36:06] ppocr INFO:                 image_shape : [3, 32, 100]\n",
            "[2025/06/08 04:36:06] ppocr INFO:             KeepKeys : \n",
            "[2025/06/08 04:36:06] ppocr INFO:                 keep_keys : ['image', 'label', 'length']\n",
            "[2025/06/08 04:36:06] ppocr INFO:     loader : \n",
            "[2025/06/08 04:36:06] ppocr INFO:         batch_size_per_card : 1\n",
            "[2025/06/08 04:36:06] ppocr INFO:         drop_last : False\n",
            "[2025/06/08 04:36:06] ppocr INFO:         num_workers : 0\n",
            "[2025/06/08 04:36:06] ppocr INFO:         shuffle : True\n",
            "[2025/06/08 04:36:06] ppocr INFO: profiler_options : None\n",
            "[2025/06/08 04:36:06] ppocr INFO: train with paddle 2.5.1 and device Place(gpu:0)\n",
            "[2025/06/08 04:36:06] ppocr INFO: Initialize indexes of datasets:['/content/rec_train_label.txt']\n",
            "[2025/06/08 04:36:06] ppocr INFO: Initialize indexes of datasets:['/content/rec_train_label.txt']\n",
            "W0608 04:36:06.584201  6235 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 7.5, Driver API Version: 12.4, Runtime API Version: 11.8\n",
            "W0608 04:36:06.584916  6235 gpu_resources.cc:149] device: 0, cuDNN Version: 90.2.\n",
            "[2025/06/08 04:36:06] ppocr INFO: train dataloader has 30 iters\n",
            "[2025/06/08 04:36:06] ppocr INFO: valid dataloader has 30 iters\n",
            "[2025/06/08 04:36:06] ppocr INFO: train from scratch\n",
            "[2025/06/08 04:36:06] ppocr INFO: During the training process, after the 0th iteration, an evaluation is run every 200 iterations\n",
            "\n",
            "\n",
            "--------------------------------------\n",
            "C++ Traceback (most recent call last):\n",
            "--------------------------------------\n",
            "No stack trace in paddle, may be caused by external reasons.\n",
            "\n",
            "----------------------\n",
            "Error Message Summary:\n",
            "----------------------\n",
            "FatalError: `Segmentation fault` is detected by the operating system.\n",
            "  [TimeInfo: *** Aborted at 1749357367 (unix time) try \"date -d @1749357367\" if you are using GNU date ***]\n",
            "  [SignalInfo: *** SIGSEGV (@0x0) received by PID 6235 (TID 0x7ff5374db480) from PID 0 ***]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!python /content/PaddleOCR/tools/train.py -c /content/rec_config.yml"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}